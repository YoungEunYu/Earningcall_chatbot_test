import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import networkx as nx
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from openai import OpenAI
import os
import plotly.express as px
import sys
from pathlib import Path
from textblob import TextBlob
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import json
from utils.topic_preprocessing import load_earnings_calls, analyze_topic_trends, extract_topics
from utils.insight_extraction import extract_complex_insights, FINANCIAL_PHRASES
import re
import altair as alt

# í˜„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# temporal_analysis.pyì—ì„œ ì§ì ‘ í•¨ìˆ˜ import
try:
    from utils.temporal_analysis import extract_temporal_data, identify_key_events
except ImportError as e:
    print(f"Import Error: {e}")
    print(f"Current directory: {current_dir}")
    print(f"Python path: {sys.path}")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))

# GPT í˜¸ì¶œ í™œì„±í™”/ë¹„í™œì„±í™” í”Œë˜ê·¸
USE_GPT = True  # GPT í˜¸ì¶œ ë¹„í™œì„±í™”

def get_chatgpt_response(prompt, context):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    if not USE_GPT:
        return "GPT call has been disabled."

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a financial analyst assistant."},
                {"role": "user", "content": f"Context: {context}\n\nQuestion: {prompt}"}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error generating response: {str(e)}"

def create_topic_network(topic_info):
    """í† í”½-ë¬¸êµ¬ ë„¤íŠ¸ì›Œí¬ ìƒì„±"""
    G = nx.Graph()
    
    # NaN ì²´í¬ ì¶”ê°€í•˜ì—¬ ìˆ˜ì •
    for _, row in topic_info.iterrows():
        topic_num = f"Topic {row['Topic_Num']}"
        
        # Top_Phrasesê°€ ë¬¸ìì—´ì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if isinstance(row['Top_Phrases'], str):
            phrases = row['Top_Phrases'].split(' | ')
            
            # í† í”½ ë…¸ë“œ ì¶”ê°€
            G.add_node(topic_num, node_type='topic', size=row['Size'])
            
            # ë¬¸êµ¬ ë…¸ë“œ ì¶”ê°€ ë° ì—£ì§€ ì—°ê²°
            for phrase in phrases:
                G.add_node(phrase, node_type='phrase', size=10)
                G.add_edge(topic_num, phrase)
    
    # ë…¸ë“œ ìœ„ì¹˜ ì‚°
    pos = nx.spring_layout(G, k=1, iterations=50)
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    # ë„¤ë“œ íŠ¸ë ˆì´ìŠ¤
    node_x = []
    node_y = []
    node_text = []
    node_size = []
    node_color = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
        node_size.append(G.nodes[node]['size'])
        # ë…¸ë“œ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
        if G.nodes[node]['node_type'] == 'topic':
            node_color.append('#0066ff')
        else:
            node_color.append('#00ff88')
    
    # ì‹œê°í™” ìƒì„±
    fig = go.Figure()
    
    # ì—£ì§€ ì¶”ê°€
    fig.add_trace(go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#666'),
        hoverinfo='none',
        mode='lines'
    ))
    
    # ë…¸ë“œ ì¶”ê°€
    fig.add_trace(go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=node_text,
        textposition="bottom center",
        marker=dict(
            size=node_size,
            color=node_color,
            line_width=2
        )
    ))
    
    fig.update_layout(
        showlegend=False,
        hovermode='closest',
        margin=dict(b=0,l=0,r=0,t=0),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d'
    )
    
    return fig

def create_sentiment_viz():
    """ê°ì„± ë¶„ì„ ì‹œê°í™” ìƒì„±"""
    # ë°ì´í„° ë¡œë“œ
    sentiment_df = pd.read_csv('data/sentiment_analysis.csv')
    keywords_df = pd.read_csv('data/keyword_analysis.csv')
    
    # 1. ê°ì„± ë¶„í¬ íŒŒì´ ì°¨íŠ¸
    sentiment_counts = {
        'Positive': len(sentiment_df[sentiment_df['sentiment'] > 0.2]),
        'Negative': len(sentiment_df[sentiment_df['sentiment'] < -0.2]),
        'Neutral': len(sentiment_df[(sentiment_df['sentiment'] >= -0.2) & 
                                  (sentiment_df['sentiment'] <= 0.2)])
    }
    
    pie_fig = go.Figure(data=[go.Pie(
        labels=list(sentiment_counts.keys()),
        values=list(sentiment_counts.values()),
        hole=.3,
        marker_colors=['#00ff88', '#ff4444', '#aaaaaa']
    )])
    
    pie_fig.update_layout(
        title="Sentiment Distribution",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white')
    )
    
    # 2. í‚¤ì›Œë“œ ë°” ì°¨íŠ¸
    keywords_fig = go.Figure()
    
    # ê¸ì • í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)
    pos_keywords = keywords_df[keywords_df['sentiment'] == 'positive'].nlargest(10, 'count')
    keywords_fig.add_trace(go.Bar(
        name='Positive',
        x=pos_keywords['keyword'],
        y=pos_keywords['count'],
        marker_color='#00ff88'
    ))
    
    # ë¶€ì • í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)
    neg_keywords = keywords_df[keywords_df['sentiment'] == 'negative'].nlargest(10, 'count')
    keywords_fig.add_trace(go.Bar(
        name='Negative',
        x=neg_keywords['keyword'],
        y=neg_keywords['count'],
        marker_color='#ff4444'
    ))
    
    keywords_fig.update_layout(
        barmode='group',
        title="Top Keywords by Sentiment",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white')
    )
    
    return pie_fig, keywords_fig

def create_enhanced_network():
    """í–¥ìƒëœ ì¸ì‚¬ì´íŠ¸ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”"""
    
    # JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    with open('data/processed/insights_network.json', 'r') as f:
        network_data = json.load(f)
    
    # ë…¸ë“œ ìƒ‰ìƒ ë§¤í•‘
    color_map = {
        'revenue': '#1f77b4',      # ìˆ˜ìµ
        'growth': '#2ca02c',       # ì„±ì¥
        'segment': '#ff7f0e',      # ì‚¬ì—…ë¶€ë¬¸
        'credit': '#d62728',       # ì‹ ìš©
        'cost': '#9467bd',         # ë¹„ìš©
        'investment': '#8c564b',   # íˆ¬ì
        'market': '#e377c2',       # ì‹œì¥
        'guidance': '#7f7f7f'      # ê°€ì´ë˜ìŠ¤
    }
    
    # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤
    node_trace = go.Scatter(
        x=[], y=[], 
        mode='markers+text',
        hoverinfo='text',
        text=[],
        textposition="bottom center",
        marker=dict(
            showscale=True,
            colorscale='YlOrRd',
            reversescale=True,
            color=[],
            size=[],
            line_width=2
        )
    )
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
    edge_trace = go.Scatter(
        x=[], y=[],
        line=dict(width=0.5, color='#888'),
        hoverinfo='text',
        mode='lines',
        text=[]
    )
    
    # ë„¤íŠ¸ì›Œí¬ ë ˆì´ì•„ì›ƒ ê³„ì‚°
    G = nx.Graph()
    
    # ë…¸ë“œ ì¶”ê°€
    for node in network_data['nodes']:
        G.add_node(node['id'], 
                  text=node['text'],
                  category=node['category'],
                  sentiment=node['sentiment'],
                  frequency=node['frequency'])
    
    # ì—£ì§€ ì¶”ê°€ - weight ì²˜ë¦¬ ìˆ˜ì •
    for edge in network_data['edges']:
        try:
            weight = edge.get('weight', 1.0)  # weightê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©
        except:
            weight = 1.0
        G.add_edge(edge['source'], edge['target'], 
                  weight=weight,
                  context=edge['context'])
    
    # ë ˆì´ì•„ì›ƒ ê³„ì‚°
    pos = nx.spring_layout(G)
    
    # ì—£ì§€ ë°ì´í„° ì¶”ê°€
    edge_trace = go.Scatter(
        x=[], y=[],
        line=dict(width=0.5, color='#888'),
        hoverinfo='text',
        mode='lines',
        text=[]
    )
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_trace['x'] += (x0, x1, None)
        edge_trace['y'] += (y0, y1, None)
        try:
            weight = G.edges[edge]['weight']
            context = G.edges[edge]['context']
            edge_trace['text'] += (f"Weight: {weight:.2f}<br>{context}",)
        except:
            edge_trace['text'] += (G.edges[edge].get('context', ''),)
    
    # ë…¸ë“œ ë°ì´í„° ì¶”ê°€
    for node in G.nodes():
        x, y = pos[node]
        node_trace['x'] += (x,)
        node_trace['y'] += (y,)
        node_info = G.nodes[node]
        
        # í˜¸ë²„ í…ìŠ¤íŠ¸
        hover_text = f"""
        {node_info['text']}
        Category: {node_info['category']}
        Sentiment: {node_info['sentiment']}
        Frequency: {node_info['frequency']}
        """
        node_trace['text'] += (hover_text,)
        
        # ë…¸ë“œ í¬ê¸° (ë¹ˆë„ ê¸°ë°˜)
        node_trace['marker']['size'] += (20 + node_info['frequency'] * 5,)
        
        # ë…¸ë“œ ìƒ‰ìƒ (í…Œê³ ë¦¬ ê¸°ë°˜)
        node_trace['marker']['color'] += (color_map[node_info['category']],)
    
    # ì‹œê°í™”
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(
                       title='Financial Insights Network',
                       titlefont_size=16,
                       showlegend=False,
                       hovermode='closest',
                       margin=dict(b=20,l=5,r=5,t=40),
                       plot_bgcolor='#2d2d2d',
                       paper_bgcolor='#2d2d2d',
                       font=dict(color='white'),
                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                   ))
    
    return fig

def create_temporal_sentiment_viz(transcript_data):
    """ì–´ë‹ì½œ ê°ì„± ë¶„ì„ ì‹œê°í™”"""
    
    temporal_df = extract_temporal_data(transcript_data)
    
    if temporal_df.empty:
        st.warning("No data could be extracted from the transcript.")
        return

    # ì‹œê°„ìˆœ ê°ì„± ì¶”ì´ ê·¸ë˜í”„
    fig = go.Figure()
    
    # ì „ì²´ ì–´ë‹ì½œì˜ ì‹œê°„ìˆœ ê°ì„± ì ìˆ˜
    fig.add_trace(go.Scatter(
        x=temporal_df.index,
        y=temporal_df['sentiment_score'].rolling(window=5).mean(),
        mode='lines',
        name='Sentiment Trend',
        line=dict(color='lightblue', width=2),
        hovertemplate="Time: %{x}<br>Sentiment: %{y:.2f}<br><extra></extra>"
    ))

    # í´ë¦­ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì •
    fig.update_layout(
        title="Earnings Call Sentiment Trend",
        xaxis_title="Time",
        yaxis_title="Sentiment Score",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white'),
        height=300,
        margin=dict(t=30, l=60, r=30, b=60)
    )

    fig.update_yaxes(range=[-1, 1])

    return fig, temporal_df

def show_transcript_popup(temporal_df, selected_index):
    """ì„ íƒëœ ì‹œì ì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ë¥¼ íŒì—…ìœ¼ë¡œ í‘œì‹œ"""
    
    # CSSë¡œ íŒì—… ìŠ¤íƒ€ì¼ ì •ì˜
    st.markdown("""
        <style>
        .transcript-popup {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            height: 80%;
            background: #1e1e1e;
            border-radius: 10px;
            padding: 20px;
            overflow-y: auto;
            z-index: 1000;
        }
        .popup-close {
            position: absolute;
            top: 10px;
            right: 10px;
            cursor: pointer;
            color: white;
            font-size: 24px;
        }
        .highlighted-text {
            background-color: rgba(138, 180, 248, 0.2);
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        </style>
    """, unsafe_allow_html=True)

    # íŒì—… ë‚´ìš©
    st.markdown(f"""
        <div class="transcript-popup">
            <div class="popup-close" onclick="window.streamlit.setComponentValue('close_popup', true)">Ã—</div>
            <h3>Transcript at {temporal_df.index[selected_index]}</h3>
            <div class="highlighted-text">
                <div style="color: #8ab4f8; margin-bottom: 5px;">
                    Sentiment Score: {temporal_df.iloc[selected_index]['sentiment_score']:.3f}
                </div>
                <div>{temporal_df.iloc[selected_index]['text']}</div>
            </div>
            <div style="margin-top: 20px;">
                <h4>Context:</h4>
                {temporal_df.iloc[max(0, selected_index-2):selected_index]['text'].str.cat(sep='<br><br>')}
                <br><br>
                {temporal_df.iloc[selected_index+1:selected_index+3]['text'].str.cat(sep='<br><br>')}
            </div>
        </div>
    """, unsafe_allow_html=True)

def get_finbert_sentiment(text):
    tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")
    model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")
    
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    outputs = model(**inputs)
    
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    positive = predictions[0][0].item()
    negative = predictions[0][1].item()
    neutral = predictions[0][2].item()
    
    # ì ìˆ˜ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ì •ê·œí™”
    sentiment_score = (positive - negative) / (positive + negative + neutral)
    
    return sentiment_score

def is_key_financial_insight(text):
    """í•µì‹¬ ê¸ˆìœµ ì •ë³´ì¸ì§€ íŒë‹¨"""
    # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
    financial_keywords = {
        # ì‹¤ì /ì„±ê³¼ ê´€ë ¨
        'revenue', 'income', 'earnings', 'profit', 'margin', 'growth',
        'billion', 'million', 'percent', 'basis points',
        
        # ì‚¬ì—… ì˜ì—­
        'banking', 'trading', 'loans', 'deposits', 'credit', 'investment',
        'assets', 'capital', 'markets',
        
        # ì§€í‘œ
        'ROE', 'ROTCE', 'CET1', 'NII', 'EPS'
    }
    
    # ë¶ˆí•„ìš”í•œ ì‹œì‘ ë¬¸êµ¬
    skip_phrases = {
        'thank you', 'good morning', 'hello', 'hi everyone',
        'next question', 'operator', 'please go ahead'
    }
    
    text_lower = text.lower()
    
    # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ë¡œ ì‹œì‘í•˜ë©´ ì œì™¸
    if any(text_lower.startswith(phrase) for phrase in skip_phrases):
        return False
        
    # ê¸ˆìœµ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸
    return any(keyword in text_lower for keyword in financial_keywords)

def get_financial_context(temporal_df, selected_index):
    """ì„ íƒëœ ì‹œì ì˜ ê¸ˆìœµ ê´€ë ¨ ë¬¸ë§¥ ì¶”ì¶œ"""
    current_text = temporal_df.iloc[selected_index]['text']
    
    if not is_key_financial_insight(current_text):
        # í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ê¸ˆìœµ ì •ë³´ê°€ ì•„ë‹ˆë©´ ì£¼ë³€ ë¬¸ë§¥ì—ì„œ ì°¾ê¸°
        context_range = range(max(0, selected_index-5), min(len(temporal_df), selected_index+5))
        for idx in context_range:
            if is_key_financial_insight(temporal_df.iloc[idx]['text']):
                return temporal_df.iloc[idx]['text'], temporal_df.iloc[idx]['sentiment_score']
    
    return current_text, temporal_df.iloc[selected_index]['sentiment_score']

def extract_quarterly_metrics(text):
    """ì–´ë‹ì½œ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì§€í‘œ ì¶”ì¶œ"""
    metrics = {}
    
    # CIB ì§€í‘œ ì¶”ì¶œ
    if "IB fees were up" in text:
        ib_fees_match = re.search(r"IB fees were up (\d+)%", text)
        if ib_fees_match:
            metrics['CIB'] = int(ib_fees_match.group(1))
    
    # AWM ì§€í‘œ ì¶”ì¶œ
    if "AUM of $" in text:
        aum_match = re.search(r"AUM of \$(\d+\.\d+) trillion.*?up (\d+)%", text)
        if aum_match:
            metrics['AWM'] = int(aum_match.group(2))
    
    # CCB ì§€í‘œ ì¶”ì¶œ
    if "CCB reported net income" in text:
        ccb_match = re.search(r"revenue of \$(\d+\.\d+) billion, which was up (\d+)%", text)
        if ccb_match:
            metrics['CCB'] = int(ccb_match.group(2))
    
    return metrics

def extract_hiring_trends(text):
    """ì–´ë‹ì½œ í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš© ê´€ë ¨ ì •ë³´ ì¶”ì¶œ"""
    hiring_info = {
        'Private Banking': 0,
        'Technology': 0,
        'Operations': 0
    }
    
    # ì±„ìš© ê´€ë ¨ í…ìŠ¤íŠ¸ ë¶„ì„
    if "growth in our private banking advisor teams" in text:
        hiring_info['Private Banking'] += 1
    if "technology and marketing" in text:
        hiring_info['Technology'] += 1
    if "operations" in text.lower():
        hiring_info['Operations'] += 1
        
    return hiring_info

def extract_strategic_focus(text):
    """ì–´ë‹ì½œ í…ìŠ¤íŠ¸ì—ì„œ ì „ëµì  íˆ¬ì ë°©í–¥ ì¶”ì¶œ"""
    strategic = {
        'ğŸŒ International': '',
        'ğŸ’» Digital': '',
        'ğŸ¦ Network': ''
    }
    
    # International ì „ëµ
    if "AWM" in text and "net inflows" in text:
        inflow_match = re.search(r"net inflows were \$(\d+) billion", text)
        if inflow_match:
            strategic['ğŸŒ International'] = f"Net inflows ${inflow_match.group(1)}B"
            
    # Digital ì „ëµ
    if "digital" in text.lower():
        digital_info = re.search(r"digital.*?([\w\s]+(?:up|increased)[\w\s]+\d+%)", text, re.I)
        if digital_info:
            strategic['ğŸ’» Digital'] = digital_info.group(1)
            
    # Branch Network
    if "retail deposit" in text.lower():
        strategic['ğŸ¦ Network'] = "Leading retail deposit share position"
        
    return strategic

def get_ai_keywords(text, period_type="quarterly"):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œì™€ ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
    if not USE_GPT:
        return {"example_keyword": 5}  # ê¸°ë³¸ í‚¤ì›Œë“œ ì˜ˆì‹œ
    
    try:
        prompt = f"""Analyze this earnings call transcript and create a word cloud representation.
        Task:
        1. Extract the most significant financial terms and insights
        2. Return only the keywords with their importance weights
        3. Focus on {period_type} performance and trends
        4. Remove all common words, numbers, and company names
        5. Combine related concepts into compound terms (e.g., 'credit_quality', 'market_share')

        Format your response ONLY as:
        keyword1:weight
        keyword2:weight
        (weights from 1-10, higher = more important)

        Transcript: {text[:4000]}...
        """
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a financial analyst."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        keywords = {}
        for line in response.choices[0].message.content.strip().split('\n'):
            if ':' in line:
                word, weight = line.strip().split(':')
                keywords[word.strip()] = int(weight)
        
        return keywords
            
    except Exception as e:
        st.error(f"Error in AI analysis: {str(e)}")
        return {}

def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="JPM Earnings Call Analysis",
        page_icon="",
        layout="wide"
    )
    
    try:
        # 1ë…„ì¹˜ ì–´ë‹ì½œ ë°ì´í„° ë¡œë“œ
        from utils.topic_preprocessing import load_earnings_calls, analyze_topic_trends, extract_topics
        earnings_calls = load_earnings_calls()
        
        # ìµœì‹  ë°ì´í„°ì˜ í† í”½ ì •ë³´
        latest_call = earnings_calls.iloc[-1]
        text_data = latest_call['text']
        
        # í† í”½ ë¶„ì„
        topic_trends = analyze_topic_trends(earnings_calls)
        
        # ìµœì‹  ë°ì´í„°ì˜ í† í”½ ì¶”ì¶œ
        topics = extract_topics([text_data])
        
        # ê°ì„± ë¶„ì„
        sentiment_fig, temporal_data = create_temporal_sentiment_viz(text_data)
        
        # ë¶„ê¸°ë³„ ë°ì´í„° ì¶”ì¶œ
        quarters = ['2024_Q3', '2024_Q2', '2024_Q1', '2023_Q4']
        quarterly_data = {
            '2023_Q4': {
                'Net Income': 9.3, 'EPS': 3.04, 'Revenue': 39.9
            },
            '2024_Q1': {
                'Net Income': 13.4, 'EPS': 4.44, 'Revenue': 42.5
            },
            '2024_Q2': {
                'Net Income': 18.1, 'EPS': 6.12, 'Revenue': 51.0
            },
            '2024_Q3': {
                'Net Income': 12.9, 'EPS': 4.37, 'Revenue': 43.3
            }
        }
        
        # ë¶„ê¸°ë³„ ì£¼ìš” ë‚´ìš© ì„¤ì •
        quarterly_highlights = {
            '2023_Q4': [
                "Return on Tangible Common Equity (ROTCE): 15%",  # ROTCE: Return on Tangible Common Equity
                "Full-year Net Income: $50 billion"
            ],
            '2024_Q1': [
                "ROTCE: 21%",  # ROTCE: Return on Tangible Common Equity
                "Strong performance in investment banking fees"
            ],
            '2024_Q2': [
                "Commercial & Investment Banking (CIB): saw a 50% increase in IB fees"  # CIB: Commercial & Investment Bank
            ],
            '2024_Q3': [
                "CIB: reported a 31% increase in IB fees"  # CIB: Commercial & Investment Bank
            ]
        }

        # ë‚˜ë¨¸ì§€ ì½”ë“œ...
        
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/raw í´ë”ì— JPM_2024_Q3.txt íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # CSS ìŠ¤íƒ€ì¼ (ê¸°ì¡´ ê²ƒ ìœ ì§€)
    st.markdown("""
        <style>
        .stApp {
            background-color: #1e1e1e;
        }
        .main-header {
            font-family: 'Helvetica Neue', sans-serif;
            padding: 1.5rem 0;
            text-align: center;
            background: linear-gradient(270deg, #0033cc 0%, #0066ff 100%);
            color: white;
            border-radius: 10px;
            margin-bottom: 2rem;
        }
        h2, h3, .subtitle {
            color: white !important;
            margin-bottom: 1rem;
        }
        .metric-card {
            background: #2d2d2d;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            text-align: center;
            margin-bottom: 1rem;
            border: 1px solid #3d3d3d;
        }
        .metric-value {
            font-size: 2rem;
            font-weight: bold;
            color: #0066ff;
        }
        .metric-label {
            color: #ffffff;
            font-size: 0.9rem;
        }
        .insights-container {
            background: #2d2d2d;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            margin: 1rem 0 2rem 0;
            border-left: 5px solid #0066ff;
            color: white;
        }
        .chart-container {
            background: #2d2d2d;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            margin: 1rem 0;
            border: 1px solid #3d3d3d;
        }
        .stMarkdown {
            color: white !important;
        }
        [data-testid="stSidebar"] {
            background-color: #2d2d2d;
            border-right: 1px solid #3d3d3d;
        }
        .analysis-card {
            background: #363636;
            padding: 1.2rem;
            border-radius: 8px;
            border: 1px solid #444;
            height: 100%;
        }
        .analysis-card h4 {
            color: #0066ff;
            margin-top: 0;
            margin-bottom: 1rem;
            font-size: 1.1rem;
            border-bottom: 2px solid #444;
            padding-bottom: 0.5rem;
        }
        .analysis-content {
            font-size: 0.95rem;
            line-height: 1.5;
        }
        .quote {
            color: #aaa;
            font-style: italic;
            margin: 0.5rem 0;
            padding-left: 1rem;
            border-left: 3px solid #0066ff;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # ë©”ì¸ 
    st.markdown("""
        <div class='main-header'>
            <h1 style='margin:0;'>JPMorgan Chase Q3 2024 Earnings Call Snapshot</h1>
            <p style='margin:0.5rem 0 0 0;'>AI-Powered Insights from the Latest Earnings Call</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Financial Analysis ì„¹ì…˜
    if 'financial_analysis' not in st.session_state:
        core_metrics_prompt = """List 3 most critical financial metrics in bullet points:
        â€¢ Format: "â†‘ Revenue $40.7B (+21% YoY)"
        â€¢ Use arrows (â†‘/â†“) to indicate direction
        â€¢ Keep each point under 30 characters
        â€¢ Numbers and percentages only"""
        
        future_outlook_prompt = """Extract 3 key forward-looking guidance points:
        â€¢ Format:
          ğŸ“Š NII: $91B expected for 2024

          ğŸ’° Expenses: $92B target

          ğŸ“ˆ Credit: 3.4% NCO rate

        â€¢ Focus on:
          1. NII forecast
          2. Expense target
          3. Credit outlook
        â€¢ Numbers only, no quotes
        â€¢ Keep each point under 25 characters"""
        
        strategy_risks_prompt = """List 3 main strategic priorities:
        â€¢ Format: "â€¢ Digital: +15% user growth"
        â€¢ One metric per strategy
        â€¢ Max 4 words per point
        â€¢ Focus on measurable goals"""
        
        st.session_state.financial_analysis = {
            'core_metrics': get_chatgpt_response(core_metrics_prompt, text_data),
            'future_outlook': get_chatgpt_response(future_outlook_prompt, text_data),
            'strategy_risks': get_chatgpt_response(strategy_risks_prompt, text_data)
        }
    
    core_metrics = st.session_state.financial_analysis['core_metrics'].replace('\n', '<br>')
    future_outlook = st.session_state.financial_analysis['future_outlook'].replace('\n', '<br>')
    strategy_risks = st.session_state.financial_analysis['strategy_risks'].replace('\n', '<br>')
    
    # JPMorgan Chase Q3 2024 Deep Dive ì„¹ì…˜
    st.markdown("""
        <div class='insights-container'>
            <div class='insights-title'>
                ğŸ“ˆ JPMorgan Chase Q3 2024 Deep Dive
            </div>
            <div style='display: grid; grid-template-columns: repeat(4, 1fr); gap: 1rem; margin-bottom: 1rem;'>
                <div class='metric-card'>
                    <div class='metric-value'>$40.7B</div>
                    <div class='metric-label'>Revenue</div>
                    <div class='metric-change'>â†‘ 21% YoY</div>
                </div>
                <div class='metric-card'>
                    <div class='metric-value'>$13.2B</div>
                    <div class='metric-label'>Net Income</div>
                    <div class='metric-change'>â†‘ 35% YoY</div>
                </div>
                <div class='metric-card'>
                    <div class='metric-value'>16.8%</div>
                    <div class='metric-label'>ROTCE</div>
                    <div class='metric-change'>â†‘ 2.1pp YoY</div>
                </div>
                <div class='metric-card'>
                    <div class='metric-value'>$4.33</div>
                    <div class='metric-label'>EPS</div>
                    <div class='metric-change'>â†‘ 38% YoY</div>
                </div>
            </div>
            <div style='display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem;'>
                <div class='analysis-card'>
                    <h4>ğŸ’° Key Performance Metrics</h4>
                    <div class='analysis-content'>{}</div>
                </div>
                <div class='analysis-card'>
                    <h4>ğŸ”® Management Outlook</h4>
                    <div class='analysis-content'>{}</div>
                </div>
                <div class='analysis-card'>
                    <h4>ğŸ¯ Strategic Insights & Risks</h4>
                    <div class='analysis-content'>{}</div>
                </div>
            </div>
        </div>
    """.format(core_metrics, future_outlook, strategy_risks), unsafe_allow_html=True)

    # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
    st.markdown("""
        <style>
        .metric-card {
            background: #363636;
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
        }
        .metric-value {
            font-size: 1.8rem;
            font-weight: bold;
            color: #0066ff;
            margin-bottom: 0.3rem;
        }
        .metric-label {
            color: #ffffff;
            font-size: 0.9rem;
            margin-bottom: 0.3rem;
        }
        .metric-change {
            color: #00ff88;
            font-size: 0.8rem;
        }
        .analysis-card {
            background: #363636;
            padding: 1.2rem;
            border-radius: 8px;
        }
        .analysis-card h4 {
            color: white;
            margin-bottom: 0.8rem;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # ì‚¬ë“œë°” ì±—ë´‡
    with st.sidebar:
        st.markdown("""
            <div style='padding: 1rem; background: linear-gradient(180deg, #0033cc 0%, #0066ff 100%); 
                        color: white; border-radius: 10px; margin-bottom: 1rem;'>
                <h3 style='margin:0;'>ğŸ’¬ Earnings Insights Assistant</h3>
            </div>
        """, unsafe_allow_html=True)
        
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        context = f"""
        Topics and key phrases from the earnings calls:
        {topic_trends.to_string()}
        
        Main discussion points from the latest earnings call:
        {text_data[:500]}...
        """
        
        if prompt := st.chat_input("Ask about the earnings call..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                response = get_chatgpt_response(prompt, context)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
        
        with st.expander("ğŸ’¡ Sample Questions", expanded=False):
            st.markdown("""
            Try asking:
            - What are the main financial highlights?
            - How is JPMorgan's investment strategy?
            - What are the key risk factors?
            - Can you explain the revenue trends?
            - What's the outlook for next quarter?
            """)
    
    # ì°¨íŠ¸ ì˜ì—­
    col1, col2 = st.columns([2,1])
    with col1:
        st.subheader("ğŸ“Š Financial Topics Evolution")
        
        topic_trend_fig = go.Figure()
        
        # ìƒ‰ìƒ ë§¤í•‘ - ë” ë‹¤ì–‘í•œ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„
        colors = {
            'Revenue & Growth': '#1f77b4',     # íŒŒë‘
            'Market & Trading': '#2ca02c',     # ì´ˆë¡
            'Credit & Risk': '#ff7f0e',        # ì£¼í™©
            'Capital & Investment': '#d62728',  # ë¹¨ê°•
            'Digital & Technology': '#9467bd',  # ë³´ë¼
            'Client & Service': '#17becf',      # ì²­ë¡
            'Strategy & Outlook': '#bcbd22',    # ì˜¬ë¦¬ë¸Œ
            'Cost & Efficiency': '#7f7f7f',     # íšŒìƒ‰
            'Operational Performance': '#e377c2' # ë¶„í™
        }

        # í† í”½ë³„ ë°ì´í„° í†µí•© ë° ì¤‘ìš”ë„ ê³„ì‚°
        topic_data_aggregated = (topic_trends.groupby(['date', 'topic'])
                               .agg({
                                   'importance': 'mean',  # ì¤‘ìš”ë„ í‰ê· 
                                   'coherence': 'mean'    # coherence í‰ê· 
                               })
                               .reset_index())
        
        # ê° ë¶„ê¸°ì˜ top 5 í† í”½ë“¤ì„ ì—°ê²°í•˜ëŠ” ì„  ê·¸ë¦¬ê¸°
        for topic in topic_trends['topic'].unique():
            topic_data = topic_data_aggregated[topic_data_aggregated['topic'] == topic]
            topic_color = colors.get(topic, '#7f7f7f')
            
            # í•´ë‹¹ í† í”½ì´ ê° ë¶„ê¸°ì˜ top 5ì— í¬í•¨ë  ë•Œë§Œ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€
            x_values = []
            y_values = []
            
            for date in topic_data_aggregated['date'].unique():
                quarter_data = topic_data_aggregated[topic_data_aggregated['date'] == date]
                quarter_top5 = quarter_data.nlargest(5, 'importance')
                
                if topic in quarter_top5['topic'].values:
                    topic_importance = quarter_data[quarter_data['topic'] == topic]['importance'].iloc[0]
                    x_values.append(date)
                    y_values.append(topic_importance)
            
            if x_values:  # ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ trace ì¶”ê°€
                topic_trend_fig.add_trace(go.Scatter(
                    x=x_values,
                    y=y_values,
                    name=topic,
                    mode='lines+markers',
                    line=dict(color=topic_color),
                    hovertemplate=
                    "Topic: " + topic + "<br>" +
                    "Importance: %{y:.1%}<br>" +
                    "<extra></extra>",
                    hoverlabel=dict(namelength=-1)
                ))
        
        topic_trend_fig.update_layout(
            xaxis_title="Earnings Call Date",
            yaxis_title="Topic Importance (%)",  # yì¶• ë ˆì´ë¸” ë³€ê²½
            height=400,
            plot_bgcolor='#2d2d2d',
            paper_bgcolor='#2d2d2d',
            font=dict(color='white'),
            margin=dict(t=30),
            showlegend=True,
            legend=dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.01,
                bgcolor="rgba(0,0,0,0.5)"
            )
        )
        
        st.plotly_chart(topic_trend_fig, use_container_width=True)
        
        st.caption("""
        **Topic Importance = Term Frequency (50%) + Section Weight (20%, Financial Highlights/Q&A) + 
        Speaker Role (20%, CEO/CFO/Analysts) + Topic Coherence (10%)**
        """)
    
    with col2:
        st.subheader("â˜ï¸ GPT Word Cloud")
        
        # ë¶„ê¸°ë³„ ë°ì´í„° ë¡œë“œ
        quarterly_files = {
            'Q3 2024': 'data/raw/JPM_2024_Q3.txt',
            'Q2 2024': 'data/raw/JPM_2024_Q2.txt',
            'Q1 2024': 'data/raw/JPM_2024_Q1.txt',
            'Q4 2023': 'data/raw/JPM_2023_Q4.txt'
        }
        
        # íƒ­ ìƒì„±
        tabs = st.tabs(list(quarterly_files.keys()) + ["Yearly View"])
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥ (yearly viewìš©)
        all_texts = []
        
        # ë¶„ê¸°ë³„ íƒ­ ì²˜ë¦¬
        for quarter, filepath in quarterly_files.items():
            try:
                with open(filepath, 'r', encoding='utf-8') as file:
                    quarter_text = file.read().strip()
                    
                if quarter_text:
                    all_texts.append(quarter_text)
                    
                    # í•´ë‹¹ ë¶„ê¸° íƒ­ì—ì„œ ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
                    with tabs[list(quarterly_files.keys()).index(quarter)]:
                        st.caption(f"AI Analysis of {quarter} Earnings Call")
                        keywords = get_ai_keywords(quarter_text, "quarterly")
                        
                        if keywords:
                            wordcloud = WordCloud(
                                width=800,
                                height=400,
                                background_color='#2d2d2d',
                                colormap='Blues',
                                prefer_horizontal=0.7,
                                min_font_size=10,
                                max_font_size=50
                            ).generate_from_frequencies(keywords)
                            
                            fig, ax = plt.subplots(figsize=(10,6))
                            ax.imshow(wordcloud)
                            ax.axis('off')
                            ax.set_facecolor('#2d2d2d')
                            fig.patch.set_facecolor('#2d2d2d')
                            st.pyplot(fig)
                            
            except Exception as e:
                st.error(f"Error processing {quarter}: {str(e)}")
        
        # Yearly View íƒ­
        with tabs[-1]:
            if all_texts:
                st.caption("AI Analysis of Full Year Earnings Calls")
                yearly_text = " ".join(all_texts)
                yearly_keywords = get_ai_keywords(yearly_text, "yearly")
                
                if yearly_keywords:
                    wordcloud = WordCloud(
                        width=800,
                        height=400,
                        background_color='#2d2d2d',
                        colormap='Blues',
                        prefer_horizontal=0.7,
                        min_font_size=10,
                        max_font_size=50
                    ).generate_from_frequencies(yearly_keywords)
                    
                    fig, ax = plt.subplots(figsize=(10,6))
                    ax.imshow(wordcloud)
                    ax.axis('off')
                    ax.set_facecolor('#2d2d2d')
                    fig.patch.set_facecolor('#2d2d2d')
                    st.pyplot(fig)
    
    # ìƒˆë¡œìš´ ì‹œê°í™” ì„¹ì…˜ ì¶”ê°€
    st.subheader("ğŸ­ Sentiment Analysis")
    pie_fig, keywords_fig = create_sentiment_viz()
    col1, col2 = st.columns(2)
    
    with col1:
        st.plotly_chart(pie_fig, use_container_width=True)
    with col2:
        st.plotly_chart(keywords_fig, use_container_width=True)
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # Speaker Sentiment Analysis ì„¹ì…˜
    st.subheader("ğŸ‘¥ Speaker Sentiment Analysis")
    
    # ë°œì–¸ì ëª©ë¡ê³¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sentiment_fig, temporal_data = create_temporal_sentiment_viz(text_data)

    # Jeremy Barnumì˜ ë°œì–¸ë§Œ í•„í„°ë§
    barnum_statements = temporal_data[temporal_data['speaker'].str.contains('Barnum', case=False, na=False)]
    
    if not barnum_statements.empty:
        st.subheader("CFO Jeremy Barnum's Statements")
        
        # ì²˜ìŒ 3ê°œì˜ ë°œì–¸ í‘œì‹œ
        statements_shown = 0
        remaining_statements = []
        
        for _, row in barnum_statements.iterrows():
            text = row['text'].strip()
            if len(text.split()) > 6:
                if statements_shown < 3:
                    st.markdown(f"""
                        <div style='background: #363636; padding: 15px; border-radius: 5px; margin: 10px 0;'>
                            <div style='color: #8ab4f8; margin-bottom: 5px;'>Sentiment Score: {row['sentiment_score']:.3f}</div>
                            <div>{text}</div>
                        </div>
                    """, unsafe_allow_html=True)
                    statements_shown += 1
                else:
                    remaining_statements.append((text, row['sentiment_score']))
        
        # ë‚˜ë¨¸ì§€ ë°œì–¸ë“¤ì€ expanderì— ë„£ê¸°
        if remaining_statements:
            with st.expander("Show More Statements", expanded=False):
                for text, score in remaining_statements:
                    st.markdown(f"""
                        <div style='background: #363636; padding: 15px; border-radius: 5px; margin: 10px 0;'>
                            <div style='color: #8ab4f8; margin-bottom: 5px;'>Sentiment Score: {score:.3f}</div>
                            <div>{text}</div>
                        </div>
                    """, unsafe_allow_html=True)
    else:
        st.info("No statements found from Jeremy Barnum in this transcript.")
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    st.subheader("ğŸ“ˆ JPM Growth & Hiring Trends")
    
    # íƒ­ ìƒì„±
    trend_tabs = st.tabs(["Business Growth", "Hiring & Tech", "Strategic Focus"])
    
    with trend_tabs[1]:
        st.caption("Hiring & Technology Investment Trends")
        st.markdown("""
            ### Quotes
            
            #### Q3 2024
            - ğŸ’¼ **Compensation & Hiring**: 
                - "continued growth in our private banking advisor teams"
                - "higher compensation, primarily revenue-related compensation"
            - ğŸ’» **Technology**: 
                - "continued growth in technology and marketing"
                - "digital platform enhancement"
            
            #### Q2 2024
            - ğŸ’¼ **Compensation & Hiring**: 
                - "expenses up 12% year-on-year, largely driven by higher compensation"
                - "field compensation and continued growth in technology and marketing"
            - ğŸ’» **Technology**: 
                - "strong customer acquisition across checking accounts and card"
                - "record number of first-time investors"
            
            #### Q1 2024
            - ğŸ’¼ **Compensation & Hiring**: 
                - "growth in our private banking advisor teams"
            - ğŸ’» **Technology**: 
                - "digital platform growth"
                - "increased mobile adoption"
            
            #### Q4 2023
            - ğŸ’¼ **Compensation & Hiring**: 
                - "higher compensation, primarily revenue-related compensation"
            - ğŸ’» **Technology**: 
                - "technology infrastructure investments"
        """)
    
    with trend_tabs[2]:
        st.caption("Strategic Investment Focus Areas - Quarterly Comparison")
        strategic_focus = {
            'Q3 2024': {
                'ğŸŒ International': 'Record quarterly revenues, $72B long-term net inflows',
                'ğŸ’» Digital': 'Ranked #1 in retail deposit share, strong customer acquisition',
                'ğŸ¦ Network': '#1 in retail deposit share for fourth straight year'
            },
            'Q2 2024': {
                'ğŸŒ International': 'IB fees up 50% YoY, #1 wallet share of 9.5%',
                'ğŸ’» Digital': 'Record first-time investors, strong customer acquisition',
                'ğŸ¦ Network': 'Strong net inflows across AWM'
            },
            'Q1 2024': {
                'ğŸŒ International': 'Strong net inflows led by equities and fixed income',
                'ï¿½ï¿½ Digital': 'Digital platform growth, increased mobile adoption',
                'ğŸ¦ Network': 'Continued branch expansion in key markets'
            },
            'Q4 2023': {
                'ğŸŒ International': 'Net inflows $52B, led by equities and fixed income',
                'ğŸ’» Digital': 'Digital users up 12%, AI projects initiated',
                'ğŸ¦ Network': 'Market share gains in deposits'
            }
        }
        
        # ë¶„ê¸°ë³„ ì „ëµ í¬ì»¤ìŠ¤ í‘œì‹œ
        for quarter, strategies in strategic_focus.items():
            st.subheader(quarter)
            for area, details in strategies.items():
                st.markdown(f"**{area}**\n- {details}")
            st.markdown("---")

    # ì‹œê°í™” ë° í…ìŠ¤íŠ¸ í‘œì‹œ
    with trend_tabs[0]:
        st.caption("Quarter-over-Quarter Financial Performance")
        # Altair chart for financial metrics with units in tooltips
        metrics_df = pd.DataFrame([
            {'Quarter': quarter, 'Metric': 'Net Income', 'Value': data['Net Income'], 'Unit': 'billion'} for quarter, data in quarterly_data.items()
        ] + [
            {'Quarter': quarter, 'Metric': 'EPS', 'Value': data['EPS'], 'Unit': 'dollars'} for quarter, data in quarterly_data.items()
        ] + [
            {'Quarter': quarter, 'Metric': 'Revenue', 'Value': data['Revenue'], 'Unit': 'billion'} for quarter, data in quarterly_data.items()
        ])

        chart = alt.Chart(metrics_df).mark_line(point=True).encode(
            x='Quarter',
            y='Value',
            color='Metric',
            tooltip=['Quarter', 'Metric', alt.Tooltip('Value', format='.2f'), 'Unit']
        ).properties(
            width=600,
            height=400
        )

        st.altair_chart(chart, use_container_width=True)

        # ë¶„ê¸°ë³„ ì£¼ìš” ë‚´ìš© í‘œì‹œ
        st.write("### Key Highlights for Each Quarter")
        for quarter, highlights in quarterly_highlights.items():
            st.subheader(quarter)
            st.write("\n".join(["- " + highlight for highlight in highlights]))

if __name__ == "__main__":
    main()

EARNINGS_CALL_INSIGHTS = {
    'financial_highlights': {
        'title': 'Financial Performance Highlights',
        'content': [
            {
                'topic': 'Revenue',
                'text': "Our revenue for the quarter was $40.7 billion, up 21% year-on-year...",
                'sentiment_score': 0.6,
                'timestamp': '10:05'
            },
            {
                'topic': 'Net Income',
                'text': "Net income of $13.2 billion reflected strong underlying performance...",
                'sentiment_score': 0.8,
                'timestamp': '10:08'
            }
        ]
    },
    'strategic_updates': {
        'title': 'Strategic Initiatives & Business Updates',
        'content': [
            {
                'topic': 'Digital Banking',
                'text': "Our digital platform saw significant growth with active users up 15%...",
                'sentiment_score': 0.7,
                'timestamp': '10:15'
            }
        ]
    },
    'future_outlook': {
        'title': 'Future Outlook & Guidance',
        'content': [
            {
                'topic': '2024 Outlook',
                'text': "We expect continued momentum in our core businesses...",
                'sentiment_score': 0.5,
                'timestamp': '10:45'
            }
        ]
    },
    'qa_highlights': {
        'title': 'Key Q&A Insights',
        'content': [
            {
                'topic': 'Credit Quality',
                'question': "Can you provide more color on credit quality trends?",
                'answer': "Credit quality remains strong across our portfolios...",
                'sentiment_score': 0.4,
                'timestamp': '11:15'
            }
        ]
    }
}
