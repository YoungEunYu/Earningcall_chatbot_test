import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import networkx as nx
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from openai import OpenAI
import os
import plotly.express as px
import sys
from pathlib import Path
from textblob import TextBlob
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import json
from utils.topic_preprocessing import load_earnings_calls, analyze_topic_trends, extract_topics
from utils.insight_extraction import extract_complex_insights, FINANCIAL_PHRASES

# í˜„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# temporal_analysis.pyì—ì„œ ì§ì ‘ í•¨ìˆ˜ import
try:
    from utils.temporal_analysis import extract_temporal_data, identify_key_events
except ImportError as e:
    print(f"Import Error: {e}")
    print(f"Current directory: {current_dir}")
    print(f"Python path: {sys.path}")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))

# GPT í˜¸ì¶œ í™œì„±í™”/ë¹„í™œì„±í™” í”Œë˜ê·¸
USE_GPT = False  # GPT í˜¸ì¶œ ë¹„í™œì„±í™”

def get_chatgpt_response(prompt, context):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    if not USE_GPT:
        return "GPT í˜¸ì¶œ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a financial analyst assistant."},
                {"role": "user", "content": f"Context: {context}\n\nQuestion: {prompt}"}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error generating response: {str(e)}"

def create_topic_network(topic_info):
    """í† í”½-ë¬¸êµ¬ ë„¤íŠ¸ì›Œí¬ ìƒì„±"""
    G = nx.Graph()
    
    # NaN ì²´í¬ ì¶”ê°€í•˜ì—¬ ìˆ˜ì •
    for _, row in topic_info.iterrows():
        topic_num = f"Topic {row['Topic_Num']}"
        
        # Top_Phrasesê°€ ë¬¸ìì—´ì¸ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if isinstance(row['Top_Phrases'], str):
            phrases = row['Top_Phrases'].split(' | ')
            
            # í† í”½ ë…¸ë“œ ì¶”ê°€
            G.add_node(topic_num, node_type='topic', size=row['Size'])
            
            # ë¬¸êµ¬ ë…¸ë“œ ì¶”ê°€ ë° ì—£ì§€ ì—°ê²°
            for phrase in phrases:
                G.add_node(phrase, node_type='phrase', size=10)
                G.add_edge(topic_num, phrase)
    
    # ë…¸ë“œ ìœ„ì¹˜ ì‚°
    pos = nx.spring_layout(G, k=1, iterations=50)
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
    edge_x = []
    edge_y = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    # ë„¤ë“œ íŠ¸ë ˆì´ìŠ¤
    node_x = []
    node_y = []
    node_text = []
    node_size = []
    node_color = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
        node_size.append(G.nodes[node]['size'])
        # ë…¸ë“œ íƒ€ì…ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
        if G.nodes[node]['node_type'] == 'topic':
            node_color.append('#0066ff')
        else:
            node_color.append('#00ff88')
    
    # ì‹œê°í™” ìƒì„±
    fig = go.Figure()
    
    # ì—£ì§€ ì¶”ê°€
    fig.add_trace(go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#666'),
        hoverinfo='none',
        mode='lines'
    ))
    
    # ë…¸ë“œ ì¶”ê°€
    fig.add_trace(go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=node_text,
        textposition="bottom center",
        marker=dict(
            size=node_size,
            color=node_color,
            line_width=2
        )
    ))
    
    fig.update_layout(
        showlegend=False,
        hovermode='closest',
        margin=dict(b=0,l=0,r=0,t=0),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d'
    )
    
    return fig

def create_sentiment_viz():
    """ê°ì„± ë¶„ì„ ì‹œê°í™” ìƒì„±"""
    # ë°ì´í„° ë¡œë“œ
    sentiment_df = pd.read_csv('data/sentiment_analysis.csv')
    keywords_df = pd.read_csv('data/keyword_analysis.csv')
    
    # 1. ê°ì„± ë¶„í¬ íŒŒì´ ì°¨íŠ¸
    sentiment_counts = {
        'Positive': len(sentiment_df[sentiment_df['sentiment'] > 0.2]),
        'Negative': len(sentiment_df[sentiment_df['sentiment'] < -0.2]),
        'Neutral': len(sentiment_df[(sentiment_df['sentiment'] >= -0.2) & 
                                  (sentiment_df['sentiment'] <= 0.2)])
    }
    
    pie_fig = go.Figure(data=[go.Pie(
        labels=list(sentiment_counts.keys()),
        values=list(sentiment_counts.values()),
        hole=.3,
        marker_colors=['#00ff88', '#ff4444', '#aaaaaa']
    )])
    
    pie_fig.update_layout(
        title="Sentiment Distribution",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white')
    )
    
    # 2. í‚¤ì›Œë“œ ë°” ì°¨íŠ¸
    keywords_fig = go.Figure()
    
    # ê¸ì • í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)
    pos_keywords = keywords_df[keywords_df['sentiment'] == 'positive'].nlargest(10, 'count')
    keywords_fig.add_trace(go.Bar(
        name='Positive',
        x=pos_keywords['keyword'],
        y=pos_keywords['count'],
        marker_color='#00ff88'
    ))
    
    # ë¶€ì • í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)
    neg_keywords = keywords_df[keywords_df['sentiment'] == 'negative'].nlargest(10, 'count')
    keywords_fig.add_trace(go.Bar(
        name='Negative',
        x=neg_keywords['keyword'],
        y=neg_keywords['count'],
        marker_color='#ff4444'
    ))
    
    keywords_fig.update_layout(
        barmode='group',
        title="Top Keywords by Sentiment",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white')
    )
    
    return pie_fig, keywords_fig

def create_enhanced_network():
    """í–¥ìƒëœ ì¸ì‚¬ì´íŠ¸ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”"""
    
    # JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    with open('data/processed/insights_network.json', 'r') as f:
        network_data = json.load(f)
    
    # ë…¸ë“œ ìƒ‰ìƒ ë§¤í•‘
    color_map = {
        'revenue': '#1f77b4',      # ìˆ˜ìµ
        'growth': '#2ca02c',       # ì„±ì¥
        'segment': '#ff7f0e',      # ì‚¬ì—…ë¶€ë¬¸
        'credit': '#d62728',       # ì‹ ìš©
        'cost': '#9467bd',         # ë¹„ìš©
        'investment': '#8c564b',   # íˆ¬ì
        'market': '#e377c2',       # ì‹œì¥
        'guidance': '#7f7f7f'      # ê°€ì´ë˜ìŠ¤
    }
    
    # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤
    node_trace = go.Scatter(
        x=[], y=[], 
        mode='markers+text',
        hoverinfo='text',
        text=[],
        textposition="bottom center",
        marker=dict(
            showscale=True,
            colorscale='YlOrRd',
            reversescale=True,
            color=[],
            size=[],
            line_width=2
        )
    )
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
    edge_trace = go.Scatter(
        x=[], y=[],
        line=dict(width=0.5, color='#888'),
        hoverinfo='text',
        mode='lines',
        text=[]
    )
    
    # ë„¤íŠ¸ì›Œí¬ ë ˆì´ì•„ì›ƒ ê³„ì‚°
    G = nx.Graph()
    
    # ë…¸ë“œ ì¶”ê°€
    for node in network_data['nodes']:
        G.add_node(node['id'], 
                  text=node['text'],
                  category=node['category'],
                  sentiment=node['sentiment'],
                  frequency=node['frequency'])
    
    # ì—£ì§€ ì¶”ê°€ - weight ì²˜ë¦¬ ìˆ˜ì •
    for edge in network_data['edges']:
        try:
            weight = edge.get('weight', 1.0)  # weightê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©
        except:
            weight = 1.0
        G.add_edge(edge['source'], edge['target'], 
                  weight=weight,
                  context=edge['context'])
    
    # ë ˆì´ì•„ì›ƒ ê³„ì‚°
    pos = nx.spring_layout(G)
    
    # ì—£ì§€ ë°ì´í„° ì¶”ê°€
    edge_trace = go.Scatter(
        x=[], y=[],
        line=dict(width=0.5, color='#888'),
        hoverinfo='text',
        mode='lines',
        text=[]
    )
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_trace['x'] += (x0, x1, None)
        edge_trace['y'] += (y0, y1, None)
        try:
            weight = G.edges[edge]['weight']
            context = G.edges[edge]['context']
            edge_trace['text'] += (f"Weight: {weight:.2f}<br>{context}",)
        except:
            edge_trace['text'] += (G.edges[edge].get('context', ''),)
    
    # ë…¸ë“œ ë°ì´í„° ì¶”ê°€
    for node in G.nodes():
        x, y = pos[node]
        node_trace['x'] += (x,)
        node_trace['y'] += (y,)
        node_info = G.nodes[node]
        
        # í˜¸ë²„ í…ìŠ¤íŠ¸
        hover_text = f"""
        {node_info['text']}
        Category: {node_info['category']}
        Sentiment: {node_info['sentiment']}
        Frequency: {node_info['frequency']}
        """
        node_trace['text'] += (hover_text,)
        
        # ë…¸ë“œ í¬ê¸° (ë¹ˆë„ ê¸°ë°˜)
        node_trace['marker']['size'] += (20 + node_info['frequency'] * 5,)
        
        # ë…¸ë“œ ìƒ‰ìƒ (í…Œê³ ë¦¬ ê¸°ë°˜)
        node_trace['marker']['color'] += (color_map[node_info['category']],)
    
    # ì‹œê°í™”
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(
                       title='Financial Insights Network',
                       titlefont_size=16,
                       showlegend=False,
                       hovermode='closest',
                       margin=dict(b=20,l=5,r=5,t=40),
                       plot_bgcolor='#2d2d2d',
                       paper_bgcolor='#2d2d2d',
                       font=dict(color='white'),
                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                   ))
    
    return fig

def create_temporal_sentiment_viz(transcript_data):
    """ì–´ë‹ì½œ ê°ì„± ë¶„ì„ ì‹œê°í™”"""
    
    temporal_df = extract_temporal_data(transcript_data)
    
    if temporal_df.empty:
        st.warning("No data could be extracted from the transcript.")
        return

    # ì‹œê°„ìˆœ ê°ì„± ì¶”ì´ ê·¸ë˜í”„
    fig = go.Figure()
    
    # ì „ì²´ ì–´ë‹ì½œì˜ ì‹œê°„ìˆœ ê°ì„± ì ìˆ˜
    fig.add_trace(go.Scatter(
        x=temporal_df.index,
        y=temporal_df['sentiment_score'].rolling(window=5).mean(),
        mode='lines',
        name='Sentiment Trend',
        line=dict(color='lightblue', width=2),
        hovertemplate="Time: %{x}<br>Sentiment: %{y:.2f}<br><extra></extra>"
    ))

    # í´ë¦­ ì´ë²¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì •
    fig.update_layout(
        title="Earnings Call Sentiment Trend",
        xaxis_title="Time",
        yaxis_title="Sentiment Score",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white'),
        height=300,
        margin=dict(t=30, l=60, r=30, b=60)
    )

    fig.update_yaxes(range=[-1, 1])

    return fig, temporal_df

def show_transcript_popup(temporal_df, selected_index):
    """ì„ íƒëœ ì‹œì ì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ë¥¼ íŒì—…ìœ¼ë¡œ í‘œì‹œ"""
    
    # CSSë¡œ íŒì—… ìŠ¤íƒ€ì¼ ì •ì˜
    st.markdown("""
        <style>
        .transcript-popup {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            height: 80%;
            background: #1e1e1e;
            border-radius: 10px;
            padding: 20px;
            overflow-y: auto;
            z-index: 1000;
        }
        .popup-close {
            position: absolute;
            top: 10px;
            right: 10px;
            cursor: pointer;
            color: white;
            font-size: 24px;
        }
        .highlighted-text {
            background-color: rgba(138, 180, 248, 0.2);
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
        }
        </style>
    """, unsafe_allow_html=True)

    # íŒì—… ë‚´ìš©
    st.markdown(f"""
        <div class="transcript-popup">
            <div class="popup-close" onclick="window.streamlit.setComponentValue('close_popup', true)">Ã—</div>
            <h3>Transcript at {temporal_df.index[selected_index]}</h3>
            <div class="highlighted-text">
                <div style="color: #8ab4f8; margin-bottom: 5px;">
                    Sentiment Score: {temporal_df.iloc[selected_index]['sentiment_score']:.3f}
                </div>
                <div>{temporal_df.iloc[selected_index]['text']}</div>
            </div>
            <div style="margin-top: 20px;">
                <h4>Context:</h4>
                {temporal_df.iloc[max(0, selected_index-2):selected_index]['text'].str.cat(sep='<br><br>')}
                <br><br>
                {temporal_df.iloc[selected_index+1:selected_index+3]['text'].str.cat(sep='<br><br>')}
            </div>
        </div>
    """, unsafe_allow_html=True)

def get_finbert_sentiment(text):
    tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")
    model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")
    
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    outputs = model(**inputs)
    
    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
    positive = predictions[0][0].item()
    negative = predictions[0][1].item()
    neutral = predictions[0][2].item()
    
    # ì ìˆ˜ë¥¼ -1ì—ì„œ 1 ì‚¬ì´ë¡œ ì •ê·œí™”
    sentiment_score = (positive - negative) / (positive + negative + neutral)
    
    return sentiment_score

def is_key_financial_insight(text):
    """í•µì‹¬ ê¸ˆìœµ ì •ë³´ì¸ì§€ íŒë‹¨"""
    # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
    financial_keywords = {
        # ì‹¤ì /ì„±ê³¼ ê´€ë ¨
        'revenue', 'income', 'earnings', 'profit', 'margin', 'growth',
        'billion', 'million', 'percent', 'basis points',
        
        # ì‚¬ì—… ì˜ì—­
        'banking', 'trading', 'loans', 'deposits', 'credit', 'investment',
        'assets', 'capital', 'markets',
        
        # ì§€í‘œ
        'ROE', 'ROTCE', 'CET1', 'NII', 'EPS'
    }
    
    # ë¶ˆí•„ìš”í•œ ì‹œì‘ ë¬¸êµ¬
    skip_phrases = {
        'thank you', 'good morning', 'hello', 'hi everyone',
        'next question', 'operator', 'please go ahead'
    }
    
    text_lower = text.lower()
    
    # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ë¡œ ì‹œì‘í•˜ë©´ ì œì™¸
    if any(text_lower.startswith(phrase) for phrase in skip_phrases):
        return False
        
    # ê¸ˆìœµ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸
    return any(keyword in text_lower for keyword in financial_keywords)

def get_financial_context(temporal_df, selected_index):
    """ì„ íƒëœ ì‹œì ì˜ ê¸ˆìœµ ê´€ë ¨ ë¬¸ë§¥ ì¶”ì¶œ"""
    current_text = temporal_df.iloc[selected_index]['text']
    
    if not is_key_financial_insight(current_text):
        # í˜„ì¬ í…ìŠ¤íŠ¸ê°€ ê¸ˆìœµ ì •ë³´ê°€ ì•„ë‹ˆë©´ ì£¼ë³€ ë¬¸ë§¥ì—ì„œ ì°¾ê¸°
        context_range = range(max(0, selected_index-5), min(len(temporal_df), selected_index+5))
        for idx in context_range:
            if is_key_financial_insight(temporal_df.iloc[idx]['text']):
                return temporal_df.iloc[idx]['text'], temporal_df.iloc[idx]['sentiment_score']
    
    return current_text, temporal_df.iloc[selected_index]['sentiment_score']

def main():
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="JPM Earnings Call Analysis",
        page_icon="",
        layout="wide"
    )
    
    try:
        # 1ë…„ì¹˜ ì–´ë‹ì½œ ë°ì´í„° ë¡œë“œ
        from utils.topic_preprocessing import load_earnings_calls, analyze_topic_trends, extract_topics
        earnings_calls = load_earnings_calls()
        
        # ìµœì‹  ë°ì´í„°ì˜ í† í”½ ì •ë³´
        latest_call = earnings_calls.iloc[-1]
        text_data = latest_call['text']
        
        # í† í”½ ë¶„ì„
        topic_trends = analyze_topic_trends(earnings_calls)
        
        # ìµœì‹  ë°ì´í„°ì˜ í† í”½ ì¶”ì¶œ
        topics = extract_topics([text_data])
        
        # ê°ì„± ë¶„ì„
        sentiment_fig, temporal_data = create_temporal_sentiment_viz(text_data)
        
        # ë‚˜ë¨¸ì§€ ì½”ë“œ...
        
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/raw í´ë”ì— JPM_2024_Q3.txt íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    # # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
    # st.write(f"Current working directory: {os.getcwd()}")

    # # Q4 2023 ì¼ ì ˆëŒ€ ê²½ë¡œ
    # q4_path = os.path.abspath('data/raw/JPM_2023_Q4.txt')
    # st.write(f"Q4 2023 absolute path: {q4_path}")

    # # íŒŒì¼ ì¡´ ì—¬ë¶€ í™•ì¸
    # st.write(f"File exists: {os.path.exists(q4_path)}")

    # # íŒŒì¼ í¬ê¸° í™•ì¸
    # st.write(f"File size: {os.path.getsize(q4_path)} bytes")

    # # íŒŒì¼ ë‚´ìš© ì§ì ‘ ì½ê¸°
    # with open(q4_path, 'r', encoding='utf-8') as f:
    #     content = f.read()
    #     st.write(f"Content length: {len(content)}")
    #     st.write("First 100 characters:", content[:100])
    
    # CSS ìŠ¤íƒ€ì¼ (ê¸°ì¡´ ê²ƒ ìœ ì§€)
    st.markdown("""
        <style>
        .stApp {
            background-color: #1e1e1e;
        }
        .main-header {
            font-family: 'Helvetica Neue', sans-serif;
            padding: 1.5rem 0;
            text-align: center;
            background: linear-gradient(270deg, #0033cc 0%, #0066ff 100%);
            color: white;
            border-radius: 10px;
            margin-bottom: 2rem;
        }
        h2, h3, .subtitle {
            color: white !important;
            margin-bottom: 1rem;
        }
        .metric-card {
            background: #2d2d2d;
            padding: 1rem;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            text-align: center;
            margin-bottom: 1rem;
            border: 1px solid #3d3d3d;
        }
        .metric-value {
            font-size: 2rem;
            font-weight: bold;
            color: #0066ff;
        }
        .metric-label {
            color: #ffffff;
            font-size: 0.9rem;
        }
        .insights-container {
            background: #2d2d2d;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            margin: 1rem 0 2rem 0;
            border-left: 5px solid #0066ff;
            color: white;
        }
        .chart-container {
            background: #2d2d2d;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            margin: 1rem 0;
            border: 1px solid #3d3d3d;
        }
        .stMarkdown {
            color: white !important;
        }
        [data-testid="stSidebar"] {
            background-color: #2d2d2d;
            border-right: 1px solid #3d3d3d;
        }
        .analysis-card {
            background: #363636;
            padding: 1.2rem;
            border-radius: 8px;
            border: 1px solid #444;
            height: 100%;
        }
        .analysis-card h4 {
            color: #0066ff;
            margin-top: 0;
            margin-bottom: 1rem;
            font-size: 1.1rem;
            border-bottom: 2px solid #444;
            padding-bottom: 0.5rem;
        }
        .analysis-content {
            font-size: 0.95rem;
            line-height: 1.5;
        }
        .quote {
            color: #aaa;
            font-style: italic;
            margin: 0.5rem 0;
            padding-left: 1rem;
            border-left: 3px solid #0066ff;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # ë©”ì¸ 
    st.markdown("""
        <div class='main-header'>
            <h1 style='margin:0;'>JPMorgan Chase Q3 2024 Earnings Call Analysis</h1>
            <p style='margin:0.5rem 0 0 0;'>AI-Powered Insights from the Latest Earnings Call</p>
        </div>
    """, unsafe_allow_html=True)
    
    # Financial Analysis ì„¹ì…˜
    if 'financial_analysis' not in st.session_state:
        core_metrics_prompt = """Extract 3-4 key financial metrics from the earnings call:
        â€¢ Focus on exact numbers and YoY changes
        â€¢ Start each point with the most important number/change
        â€¢ Format: "Revenue up 15% YoY to $12.3B"
        â€¢ Keep each point to one line
        â€¢ Include only the most significant metrics"""
        
        future_outlook_prompt = """Extract 3-4 key points about future outlook:
        â€¢ Focus on specific guidance and targets
        â€¢ Start with the most important prediction/target
        â€¢ Include direct quotes from CEO/CFO
        â€¢ Format: "2024 Target: $X revenue, citing 'relevant quote'"
        â€¢ Keep each point to one line"""
        
        strategy_risks_prompt = """Extract 3-4 key strategic points and risks:
        â€¢ Focus on concrete plans and specific challenges
        â€¢ Start each point with the key strategy/risk
        â€¢ Include management's direct responses
        â€¢ Format: "Digital Banking: Investing $XB in tech, 'relevant quote'"
        â€¢ Keep each point to one line"""
        
        st.session_state.financial_analysis = {
            'core_metrics': get_chatgpt_response(core_metrics_prompt, text_data),
            'future_outlook': get_chatgpt_response(future_outlook_prompt, text_data),
            'strategy_risks': get_chatgpt_response(strategy_risks_prompt, text_data)
        }
    
    core_metrics = st.session_state.financial_analysis['core_metrics'].replace('\n', '<br>')
    future_outlook = st.session_state.financial_analysis['future_outlook'].replace('\n', '<br>')
    strategy_risks = st.session_state.financial_analysis['strategy_risks'].replace('\n', '<br>')
    
    st.markdown("""
        <div class='insights-container'>
            <div class='insights-title'>
                ğŸ“ˆ JPMorgan Chase Q3 2024 Deep Dive
            </div>
            <div style='display: grid; grid-template-columns: repeat(3, 1fr); gap: 1rem;'>
                <div class='analysis-card'>
                    <h4>ğŸ’° Key Performance Metrics</h4>
                    <div class='analysis-content'>{}</div>
                </div>
                <div class='analysis-card'>
                    <h4>ğŸ”® Management Outlook</h4>
                    <div class='analysis-content'>{}</div>
                </div>
                <div class='analysis-card'>
                    <h4>ğŸ¯ Strategic Insights & Risks</h4>
                    <div class='analysis-content'>{}</div>
                </div>
            </div>
        </div>
    """.format(core_metrics, future_outlook, strategy_risks), unsafe_allow_html=True)
    
    # ì‚¬ë“œë°” ì±—ë´‡
    with st.sidebar:
        st.markdown("""
            <div style='padding: 1rem; background: linear-gradient(180deg, #0033cc 0%, #0066ff 100%); 
                        color: white; border-radius: 10px; margin-bottom: 1rem;'>
                <h3 style='margin:0;'>ğŸ’¬ AI Financial Analyst</h3>
            </div>
        """, unsafe_allow_html=True)
        
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        context = f"""
        Topics and key phrases from the earnings calls:
        {topic_trends.to_string()}
        
        Main discussion points from the latest earnings call:
        {text_data[:500]}...
        """
        
        if prompt := st.chat_input("Ask about the earnings call..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                response = get_chatgpt_response(prompt, context)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
        
        with st.expander("ğŸ’¡ Sample Questions", expanded=False):
            st.markdown("""
            Try asking:
            - What are the main financial highlights?
            - How is JPMorgan's investment strategy?
            - What are the key risk factors?
            - Can you explain the revenue trends?
            - What's the outlook for next quarter?
            """)
    
    # ìš” ì§€í‘œ í–‰
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
            <div class='metric-card'>
                <div class='metric-value'>{}</div>
                <div class='metric-label'>Topics Identified</div>
            </div>
        """.format(len(topic_trends['topic'].unique())), unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
            <div class='metric-card'>
                <div class='metric-value'>{}</div>
                <div class='metric-label'>Total Phrases Analyzed</div>
            </div>
        """.format(len(topic_trends)), unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
            <div class='metric-card'>
                <div class='metric-value'>{}</div>
                <div class='metric-label'>Key Topics</div>
            </div>
        """.format(len(topic_trends[topic_trends['coherence'] > topic_trends['coherence'].mean()])), unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
            <div class='metric-card'>
                <div class='metric-value'>Q3 2024</div>
                <div class='metric-label'>Earnings Period</div>
            </div>
        """, unsafe_allow_html=True)
    
    # ì°¨íŠ¸ ì˜ì—­
    col1, col2 = st.columns([2,1])
    
    with col1:
        st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
        st.subheader("ğŸ“Š Financial Topics Evolution")
        
        topic_trend_fig = go.Figure()
        
        # ìƒ‰ìƒ ë§¤í•‘ - ë” ë‹¤ì–‘í•œ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„
        colors = {
            'Revenue & Growth': '#1f77b4',     # íŒŒë‘
            'Market & Trading': '#2ca02c',     # ì´ˆë¡
            'Credit & Risk': '#ff7f0e',        # ì£¼í™©
            'Capital & Investment': '#d62728',  # ë¹¨ê°•
            'Digital & Technology': '#9467bd',  # ë³´ë¼
            'Client & Service': '#17becf',      # ì²­ë¡
            'Strategy & Outlook': '#bcbd22',    # ì˜¬ë¦¬ë¸Œ
            'Cost & Efficiency': '#7f7f7f',     # íšŒìƒ‰
            'Operational Performance': '#e377c2' # ë¶„í™
        }

        # í† í”½ë³„ ë°ì´í„° í†µí•© ë° ì¤‘ìš”ë„ ê³„ì‚°
        topic_data_aggregated = (topic_trends.groupby(['date', 'topic'])
                               .agg({
                                   'importance': 'mean',  # ì¤‘ìš”ë„ í‰ê· 
                                   'coherence': 'mean'    # coherence í‰ê· 
                               })
                               .reset_index())
        
        # ê° ë¶„ê¸°ì˜ top 5 í† í”½ë“¤ì„ ì—°ê²°í•˜ëŠ” ì„  ê·¸ë¦¬ê¸°
        for topic in topic_trends['topic'].unique():
            topic_data = topic_data_aggregated[topic_data_aggregated['topic'] == topic]
            topic_color = colors.get(topic, '#7f7f7f')
            
            # í•´ë‹¹ í† í”½ì´ ê° ë¶„ê¸°ì˜ top 5ì— í¬í•¨ë  ë•Œë§Œ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ê°€
            x_values = []
            y_values = []
            
            for date in topic_data_aggregated['date'].unique():
                quarter_data = topic_data_aggregated[topic_data_aggregated['date'] == date]
                quarter_top5 = quarter_data.nlargest(5, 'importance')
                
                if topic in quarter_top5['topic'].values:
                    topic_importance = quarter_data[quarter_data['topic'] == topic]['importance'].iloc[0]
                    x_values.append(date)
                    y_values.append(topic_importance)
            
            if x_values:  # ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ trace ì¶”ê°€
                topic_trend_fig.add_trace(go.Scatter(
                    x=x_values,
                    y=y_values,
                    name=topic,
                    mode='lines+markers',
                    line=dict(color=topic_color),
                    hovertemplate=
                    "Topic: " + topic + "<br>" +
                    "Importance Score: %{y:.3f}<br>" +
                    "<extra></extra>",
                    hoverlabel=dict(namelength=-1)
                ))
        
        topic_trend_fig.update_layout(
            xaxis_title="Earnings Call Date",
            yaxis_title="Topic Importance Score",  # yì¶• ë ˆì´ë¸” ë³€ê²½
            height=400,
            plot_bgcolor='#2d2d2d',
            paper_bgcolor='#2d2d2d',
            font=dict(color='white'),
            margin=dict(t=30),
            showlegend=True,
            legend=dict(
                yanchor="top",
                y=0.99,
                xanchor="left",
                x=0.01,
                bgcolor="rgba(0,0,0,0.5)"
            )
        )
        
        st.plotly_chart(topic_trend_fig, use_container_width=True)
        
        st.caption("""
        **Importance Score (0-1) = Term Frequency (35%) + Section Weight (35%) + Speaker Role (20%) + Topic Coherence (10%)**
        """)
        
        # í† í”½ë³„ ì£¼ìš” êµ¬ì ˆ í‘œì‹œ
        st.markdown("### Key Phrases by Topic")
        for topic in topic_trends['topic'].unique():
            topic_data = topic_trends[topic_trends['topic'] == topic].iloc[-1]
            terms = [term for term, _ in eval(str(topic_data['terms']))]
            
            st.markdown(f"""
                <div style='background: #363636; padding: 10px; border-radius: 5px; margin: 5px 0;'>
                    <b>{topic}</b>: {', '.join(terms[:5])}
                </div>
            """, unsafe_allow_html=True)
            
        st.markdown("</div>", unsafe_allow_html=True)
    
    with col2:
        st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
        st.subheader("â˜ï¸ AI-Powered Word Cloud")
        
        def get_ai_keywords(text, period_type="quarterly"):
            """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í•µì‹ í‚¤ì›Œë“œì™€ ê°€ì¤‘ì¹˜ ì¶”ì¶œ"""
            if not USE_GPT:
                # GPT ë¹„í™œì„±í™” ì‹œ ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§ ì¶”ê°€
                # ì˜ˆì‹œ: ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
                keywords = {"example_keyword": 5}  # ê¸°ë³¸ í‚¤ì›Œë“œ ì˜ˆì‹œ
                return keywords

            try:
                prompt = f"""Analyze this earnings call transcript and create a word cloud representation.

                Task:
                1. Extract the most significant financial terms and insights
                2. Return only the keywords with their importance weights
                3. Focus on {period_type} performance and trends
                4. Remove all common words, numbers, and company names
                5. Combine related concepts into compound terms (e.g., 'credit_quality', 'market_share')

                Format your response ONLY as:
                keyword1:weight
                keyword2:weight
                (weights from 1-10, higher = more important)

                Transcript: {text[:4000]}...
                """
                
                response = client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "You are a financial analyst."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=500
                )
                
                # GPT ì‘ë‹µì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                keywords = {}
                for line in response.choices[0].message.content.strip().split('\n'):
                    if ':' in line:
                        word, weight = line.strip().split(':')
                        keywords[word.strip()] = int(weight)
                
                return keywords
                
            except Exception as e:
                st.error(f"Error in AI analysis: {str(e)}")
                return {}

        # ë¶„ê¸°ë³„ ë°ì´í„° ë¡œë“œ
        quarterly_files = {
            'Q3 2024': 'data/raw/JPM_2024_Q3.txt',
            'Q2 2024': 'data/raw/JPM_2024_Q2.txt',
            'Q1 2024': 'data/raw/JPM_2024_Q1.txt',
            'Q4 2023': 'data/raw/JPM_2023_Q4.txt'
        }
        
        # íƒ­ ìƒì„±
        tabs = st.tabs(list(quarterly_files.keys()) + ["Yearly View"])
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥ (yearly view)
        all_texts = []
        
        # ë¶„ê¸°ë³„ íƒ­ ì²˜ë¦¬
        for quarter, filepath in quarterly_files.items():
            try:
                with open(filepath, 'r', encoding='utf-8') as file:
                    quarter_text = file.read().strip()
                    
                if quarter_text:
                    all_texts.append(quarter_text)
                    
                    # í•´ë‹¹ ë¶„ê¸° íƒ­ì—ì„œ ì›Œë“œí´ë¼ìš°ë“œ ì‹œ
                    with tabs[list(quarterly_files.keys()).index(quarter)]:
                        st.caption(f"AI Analysis of {quarter} Earnings Call")
                        keywords = get_ai_keywords(quarter_text, "quarterly")
                        
                        if keywords:
                            wordcloud = WordCloud(
                                width=800,
                                height=400,
                                background_color='#2d2d2d',
                                colormap='Blues',
                                prefer_horizontal=0.7,
                                min_font_size=10,
                                max_font_size=50
                            ).generate_from_frequencies(keywords)
                            
                            fig, ax = plt.subplots(figsize=(10,6))
                            ax.imshow(wordcloud)
                            ax.axis('off')
                            ax.set_facecolor('#2d2d2d')
                            fig.patch.set_facecolor('#2d2d2d')
                            st.pyplot(fig)
                            
            except Exception as e:
                st.error(f"Error processing {quarter}")
        
        # Yearly View íƒ­
        with tabs[-1]:
            if all_texts:
                st.caption("AI Analysis of Full Year Earnings Calls")
                yearly_text = " ".join(all_texts)
                yearly_keywords = get_ai_keywords(yearly_text, "yearly")
                
                if yearly_keywords:
                    wordcloud = WordCloud(
                        width=800,
                        height=400,
                        background_color='#2d2d2d',
                        colormap='Blues',
                        prefer_horizontal=0.7,
                        min_font_size=10,
                        max_font_size=50
                    ).generate_from_frequencies(yearly_keywords)
                    
                    fig, ax = plt.subplots(figsize=(10,6))
                    ax.imshow(wordcloud)
                    ax.axis('off')
                    ax.set_facecolor('#2d2d2d')
                    fig.patch.set_facecolor('#2d2d2d')
                    st.pyplot(fig)
        
        st.markdown("</div>", unsafe_allow_html=True)
    
    # ë„¤íŠ¸ì›Œí¬ ë§µ
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ”„ Financial Topic Network")
    
    try:
        from utils.visualization import create_topic_network
        network_fig = create_topic_network(topics)
        st.plotly_chart(network_fig, use_container_width=True)
    except Exception as e:
        st.error(f"Error creating network visualization: {str(e)}")
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # ìƒˆë¡œìš´ ì‹œê°í™” ì„¹ì…˜ ì¶”ê°€ (ì°¨íŠ¸ ì˜ì—­ ë‹¤ìŒì—)
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ­ Sentiment Analysis")
    
    # ê°ì„± ë¶„ì„ ì‹œê°í™”
    pie_fig, keywords_fig = create_sentiment_viz()
    col1, col2 = st.columns(2)
    
    with col1:
        st.plotly_chart(pie_fig, use_container_width=True)
    with col2:
        st.plotly_chart(keywords_fig, use_container_width=True)
    
    st.markdown("</div>", unsafe_allow_html=True)
    
    # í–¥ìƒëœ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ”„ Enhanced Keyword Network")
    network_fig = create_enhanced_network()
    st.plotly_chart(network_fig, use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

    # ì‹œê³„ì—´ ë¶„ì„ ì¶”ê°€
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ“ˆ Time Series Analysis of Financial Metrics")

    # ì‹œê³„ì—´ ë°ì´í„° ë¡œë“œ
    time_series_data = pd.read_csv('data/time_series_data.csv')  # ì‹œê³„ì—´ ë°ì´í„° íŒŒì¼ ë¡œë“œ

    # ì‹œê³„ì—´ ë°ì´í„° ì‹œê°í™”
    time_series_fig = go.Figure()

    # ê° ìœµ ì§€í‘œ ëŒ€í•´ ì‹œê³„ì—´ ê·¸ë˜í”„ ì¶”ê°€
    for metric in ['revenue', 'profit', 'expenses']:  # ì˜ˆì‹œë¡œ ìˆ˜ìµ, ì´ìµ, ë¹„ìš© ì§€í‘œ ì‚¬ìš©
        time_series_fig.add_trace(go.Scatter(
            x=time_series_data['date'],
            y=time_series_data[metric],
            mode='lines+markers',
            name=metric.capitalize(),
            hovertemplate="<b>%{x}</b><br>" +
                          f"{metric.capitalize()}: %{{y:.2f}}<br>" +
                          "<extra></extra>"
        ))

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    time_series_fig.update_layout(
        title="Time Series Analysis of Financial Metrics",
        xaxis_title="Date",
        yaxis_title="Value",
        plot_bgcolor='#2d2d2d',
        paper_bgcolor='#2d2d2d',
        font=dict(color='white'),
        height=400
    )

    # ì‹œê°í™” ì¶œë ¥
    st.plotly_chart(time_series_fig, use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

    # Speaker Sentiment Analysis ì„¹ì…˜
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ‘¥ Speaker Sentiment Analysis")
    
    # ë°œì–¸ì ëª©ë¡ê³¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    sentiment_fig, temporal_data = create_temporal_sentiment_viz(text_data)

    # Jeremy Barnumì˜ ë°œì–¸ë§Œ í•„í„°ë§
    barnum_statements = temporal_data[temporal_data['speaker'].str.contains('Barnum', case=False, na=False)]
    
    if not barnum_statements.empty:
        st.subheader("CFO Jeremy Barnum's Statements")
        
        # ì²˜ìŒ 3ê°œì˜ ë°œì–¸ í‘œì‹œ
        statements_shown = 0
        remaining_statements = []
        
        for _, row in barnum_statements.iterrows():
            text = row['text'].strip()
            if len(text.split()) > 6:
                if statements_shown < 3:
                    st.markdown(f"""
                        <div style='background: #363636; padding: 15px; border-radius: 5px; margin: 10px 0;'>
                            <div style='color: #8ab4f8; margin-bottom: 5px;'>Sentiment Score: {row['sentiment_score']:.3f}</div>
                            <div>{text}</div>
                        </div>
                    """, unsafe_allow_html=True)
                    statements_shown += 1
                else:
                    remaining_statements.append((text, row['sentiment_score']))
        
        # ë‚˜ë¨¸ì§€ ë°œì–¸ë“¤ì€ expanderì— ë„£ê¸°
        if remaining_statements:
            with st.expander("Show More Statements", expanded=False):
                for text, score in remaining_statements:
                    st.markdown(f"""
                        <div style='background: #363636; padding: 15px; border-radius: 5px; margin: 10px 0;'>
                            <div style='color: #8ab4f8; margin-bottom: 5px;'>Sentiment Score: {score:.3f}</div>
                            <div>{text}</div>
                        </div>
                    """, unsafe_allow_html=True)
    else:
        st.info("No statements found from Jeremy Barnum in this transcript.")

    st.markdown("</div>", unsafe_allow_html=True)

    # ê°ì„± ë¶„ì„ ì„¹ì…˜
    st.markdown("<div class='chart-container'>", unsafe_allow_html=True)
    st.subheader("ğŸ­ Earnings Call Sentiment Analysis")

    # ê°ì„± ë¶„ì„ ì‹œê°í™” ìƒì„±
    sentiment_fig, temporal_data = create_temporal_sentiment_viz(text_data)

    # ê·¸ë˜í”„ í‘œì‹œ
    st.plotly_chart(sentiment_fig, use_container_width=True)

    # ì„ íƒê¸° ì¶”ê°€
    if not temporal_data.empty:
        selected_index = st.select_slider(
            "Select a point in time",
            options=range(len(temporal_data)),
            format_func=lambda x: f"Time {x}"
        )

        # ê¸ˆìœµ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ë° í‘œì‹œ
        insight_text, sentiment = get_financial_context(temporal_data, selected_index)
        if is_key_financial_insight(insight_text):
            st.markdown(f"""
                <div style='background: #363636; padding: 15px; border-radius: 5px; margin: 10px 0;'>
                    <div style='color: #8ab4f8; margin-bottom: 5px;'>Financial Insight (Sentiment: {sentiment:.3f})</div>
                    <div>{insight_text}</div>
                </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()

EARNINGS_CALL_INSIGHTS = {
    'financial_highlights': {
        'title': 'Financial Performance Highlights',
        'content': [
            {
                'topic': 'Revenue',
                'text': "Our revenue for the quarter was $40.7 billion, up 21% year-on-year...",
                'sentiment_score': 0.6,
                'timestamp': '10:05'
            },
            {
                'topic': 'Net Income',
                'text': "Net income of $13.2 billion reflected strong underlying performance...",
                'sentiment_score': 0.8,
                'timestamp': '10:08'
            }
        ]
    },
    'strategic_updates': {
        'title': 'Strategic Initiatives & Business Updates',
        'content': [
            {
                'topic': 'Digital Banking',
                'text': "Our digital platform saw significant growth with active users up 15%...",
                'sentiment_score': 0.7,
                'timestamp': '10:15'
            }
        ]
    },
    'future_outlook': {
        'title': 'Future Outlook & Guidance',
        'content': [
            {
                'topic': '2024 Outlook',
                'text': "We expect continued momentum in our core businesses...",
                'sentiment_score': 0.5,
                'timestamp': '10:45'
            }
        ]
    },
    'qa_highlights': {
        'title': 'Key Q&A Insights',
        'content': [
            {
                'topic': 'Credit Quality',
                'question': "Can you provide more color on credit quality trends?",
                'answer': "Credit quality remains strong across our portfolios...",
                'sentiment_score': 0.4,
                'timestamp': '11:15'
            }
        ]
    }
}

